{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext,SparkConf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = \"local\"\n",
    "if len(sys.argv) == 2:\n",
    "    master = argv[1]\n",
    "sc = SparkContext(master,\"WordCount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在控制台输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas->2\n",
      "i->1\n",
      "like->1\n",
      "spark->1\n",
      "pyspark->2\n"
     ]
    }
   ],
   "source": [
    "inputdata = sc.textFile(\"./data/inputFiles/wordcount.txt\")\n",
    "result = inputdata.flatMap(lambda x : x.split(\" \")).countByValue()\n",
    "# print(result) # defaultdict(<class 'int'>, {'pandas': 2, 'i': 1, 'like': 1, 'spark': 1, 'pyspark': 2})\n",
    "for key in result:\n",
    "#     print(key,result[key])\n",
    "    print(\"{}->{}\".format(key,result[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pandas', 2), ('i', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = inputdata.flatMap(lambda x:x.split(\" \")).map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y)\n",
    "result2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('pandas', 2), ('i', 1), ('like', 1), ('spark', 1), ('pyspark', 2)], list)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = result2.collect()\n",
    "col,type(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将结果写入txt文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "outputPath = \"./data/outputFiles\"\n",
    "if os.path.exists(outputPath):\n",
    "#     os.remove(outputPath) # 使用os.remove()方法，会出现拒绝访问的错误\n",
    "    shutil.rmtree(outputPath)\n",
    "result2.saveAsTextFile(outputPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
